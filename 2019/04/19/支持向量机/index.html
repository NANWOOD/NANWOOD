<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.9.0">
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
    
    <title>
        支持向量机 |
        
        NANWOOD&#39;S BLOG</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="SVM简介支持向量机(Support Vector Machine)是Cortes和Vapnik于1995年首先提出的，它在解决小样本、非线性及高维模式识别中表现出许多特有的优势，并能够推广应用到函数拟合等其他机器学习问题中。支持向量机方法是建立在统计学习理论的VC 维理论和结构风险最小原理基础上的，根据有限的样本信息在模型的复杂性（即对特定训练样本的学习精度，Accuracy）和学习能力（即无错">
<meta property="og:type" content="article">
<meta property="og:title" content="支持向量机">
<meta property="og:url" content="http://zn0419.cn/2019/04/19/支持向量机/index.html">
<meta property="og:site_name" content="NANWOOD&#39;S BLOG">
<meta property="og:description" content="SVM简介支持向量机(Support Vector Machine)是Cortes和Vapnik于1995年首先提出的，它在解决小样本、非线性及高维模式识别中表现出许多特有的优势，并能够推广应用到函数拟合等其他机器学习问题中。支持向量机方法是建立在统计学习理论的VC 维理论和结构风险最小原理基础上的，根据有限的样本信息在模型的复杂性（即对特定训练样本的学习精度，Accuracy）和学习能力（即无错">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2019-11-04T17:05:44.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="支持向量机">
<meta name="twitter:description" content="SVM简介支持向量机(Support Vector Machine)是Cortes和Vapnik于1995年首先提出的，它在解决小样本、非线性及高维模式识别中表现出许多特有的优势，并能够推广应用到函数拟合等其他机器学习问题中。支持向量机方法是建立在统计学习理论的VC 维理论和结构风险最小原理基础上的，根据有限的样本信息在模型的复杂性（即对特定训练样本的学习精度，Accuracy）和学习能力（即无错">
    
    
    
        
            <link rel="stylesheet" href="http://zn0419.cn/css/markdown.css">
        
            <link rel="stylesheet" href="http://zn0419.cn/css/july.css"><!-- hexo-inject:begin --><!-- hexo-inject:end -->
        
    
</head>
<body>

<!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="banner-outer" class="hidden">
    <div id="banner-image" style="background-image: url(undefined)"></div>
    <img src="https://imgchr.com/i/DYWReK" id="avatar">
</div>

<div id="menu-outer">
    <div id="menu-inner">
        
            <a class="false" href="http://zn0419.cn/index.html">Home</a>
        
            <a class="false" href="http://zn0419.cn/archives/index.html">Archives</a>
        
            <a class="false" href="http://zn0419.cn/about/index.html">About</a>
        
    </div>
</div>

<div id="content-outer" class="container">
    <div id="content-inner">
        <article id="post">
    <h1 id="post-title">支持向量机</h1>
    <time id="post-date" datetime="2019-04-19T08:18:48.000Z">
        April 19, 2019
    </time>
    <div id="post-content" class="markdown-body">
        <h3 id="SVM简介"><a href="#SVM简介" class="headerlink" title="SVM简介"></a>SVM简介</h3><p>支持向量机(Support Vector Machine)是Cortes和Vapnik于1995年首先提出的，它在解决小样本、非线性及高维模式识别中表现出许多特有的优势，并能够推广应用到函数拟合等其他机器学习问题中。<br>支持向量机方法是建立在统计学习理论的VC 维理论和结构风险最小原理基础上的，根据有限的样本信息在模型的复杂性（即对特定训练样本的学习精度，Accuracy）和学习能力（即无错误地识别任意样本的能力）之间寻求最佳折衷，以期获得最好的推广能力。<br><br></p>
<h3 id="线性分类"><a href="#线性分类" class="headerlink" title="线性分类"></a>线性分类</h3><p>给定训练样本集 $ D=((x_1,y_1),(x_2,y_2),…,(x_m,y_m)),y_i\in\{-1,1\} $，线性分类器基于训练样本集D找到一个超平面 $ f(x)=W^Tx+b$ 区分两类数据。<br>当$ f(x)&gt;0 $时表示$ y=1 $的点，$ f(x)<0 $时表示$ y="-1" $的点，当$ f(x)="0" $时，表示该点在超平面上。当超平面距离两边的数据间距越大，则表示该超平面抗干扰性越好 <br></0></p>
<h3 id="支持向量"><a href="#支持向量" class="headerlink" title="支持向量"></a>支持向量</h3><p><br></p>
<script type="math/tex; mode=display">{w^Tx_i+b\geq1,y_i=1\atop w^Tx_i+b\leq-1,y_i=-1}</script><p><em>支持向量</em> 就是使得上式等号成立的，最靠近两条虚边界线的向量。<br>我们可以通过计算得到每一样本点$x$到超平面的距离为 $ r=\frac{|w^Tx+b|}{||w||} $<br>支持向量满足上述等式，由$w^Tx_0+b=0$($x_0$为垂点)可得 $ r=\frac{|w^Tx+b|}{||w||} $<br>推出 $ r=\frac{2}{||w||} $<br>得SVM的基本型</p>
<script type="math/tex; mode=display">max\frac{2}{||w||}\atop{s.t.y_i(w^Tx_i+b)\geq1,i=1,2,...,m}</script><p>等价于</p>
<script type="math/tex; mode=display">min\frac{1}{2}||w||^2\atop{s.t.y_i(w^Tx_i+b\geq,i=1,2,...m)}</script><p>使用拉格朗日乘数法求解</p>

    </div>
</article>

<div id="paginator">
    
</div>

    </div>
</div>

<div id="bottom-outer">
    <div id="bottom-inner">
        <div style="margin-left: 2%;">
        2019-2020
        </div> 
        <div style="margin-left: 2%;">
            NANWOOD
        </div> 
        <div href="http://www.beian.miit.gov.cn" style="margin-left: 2%;">
            浙ICP备19037221号
        </div>
    </div>
</div>

<div id="to-top">
    <i class="iconfont icon-up"></i>
</div>


    
        <script src="http://zn0419.cn/js/jquery-3.4.1.min.js"></script>
    
        <script src="http://zn0419.cn/js/highlight-9.13.1.min.js"></script>
    
        <script src="http://zn0419.cn/js/transition.js"></script>
    
        <script src="http://zn0419.cn/js/smooth-scroll.min.js"></script>
    



    <script>
      $(function () {
        $('#banner-outer').addClass('fade-out')
        $('#menu-outer').addClass('fade-show')

        $('pre').each(function (i, block) {
          hljs.highlightBlock(block);
        });
      })
    </script>


<script>
  $(function () {
    $(window).scroll(function () {
      if ($(window).scrollTop() > 150) {
        $("#to-top").fadeIn();
      } else {
        $("#to-top").fadeOut();
      }
    });
    $("#to-top").click(function () {
      $("body,html").animate({scrollTop: 0}, 500);
      return false;
    })
  })
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!-- <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script> -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->

</body>
</html>
